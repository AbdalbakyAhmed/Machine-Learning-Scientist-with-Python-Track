{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b593d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369eb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "volunteer = pd.read_csv(\"../volunteer_opportunities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07bbd258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prop_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Park_Name</th>\n",
       "      <th>Length</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Other_Details</th>\n",
       "      <th>Accessible</th>\n",
       "      <th>Limited_Access</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B057</td>\n",
       "      <td>Salt Marsh Nature Trail</td>\n",
       "      <td>Enter behind the Salt Marsh Nature Center, loc...</td>\n",
       "      <td>Marine Park</td>\n",
       "      <td>0.8 miles</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;The first half of this mile-long trail foll...</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B073</td>\n",
       "      <td>Lullwater</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>1.0 mile</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Explore the Lullwater to see how nature thrive...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B073</td>\n",
       "      <td>Midwood</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.75 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Step back in time with a walk through Brooklyn...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B073</td>\n",
       "      <td>Peninsula</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Discover how the Peninsula has changed over th...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B073</td>\n",
       "      <td>Waterfall</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Trace the source of the Lake on the Waterfall ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prop_ID                     Name  \\\n",
       "0    B057  Salt Marsh Nature Trail   \n",
       "1    B073                Lullwater   \n",
       "2    B073                  Midwood   \n",
       "3    B073                Peninsula   \n",
       "4    B073                Waterfall   \n",
       "\n",
       "                                            Location      Park_Name  \\\n",
       "0  Enter behind the Salt Marsh Nature Center, loc...    Marine Park   \n",
       "1  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "2  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "3  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "4  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "\n",
       "       Length Difficulty                                      Other_Details  \\\n",
       "0   0.8 miles       None  <p>The first half of this mile-long trail foll...   \n",
       "1    1.0 mile       Easy  Explore the Lullwater to see how nature thrive...   \n",
       "2  0.75 miles       Easy  Step back in time with a walk through Brooklyn...   \n",
       "3   0.5 miles       Easy  Discover how the Peninsula has changed over th...   \n",
       "4   0.5 miles       Easy  Trace the source of the Lake on the Waterfall ...   \n",
       "\n",
       "  Accessible Limited_Access  lat  lon  \n",
       "0          Y              N  NaN  NaN  \n",
       "1          N              N  NaN  NaN  \n",
       "2          N              N  NaN  NaN  \n",
       "3          N              N  NaN  NaN  \n",
       "4          N              N  NaN  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiking = pd.read_json(\"../hiking.json\")\n",
    "hiking.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64bad06",
   "metadata": {},
   "source": [
    "### Encoding categorical variables - binary\n",
    "\n",
    "Take a look at the hiking dataset. There are several columns here that need encoding, one of which is the Accessible column, which needs to be encoded in order to be modeled. Accessible is a binary feature, so it has two values - either Y or N - so it needs to be encoded into 1s and 0s. Use scikit-learn's LabelEncoder method to do that transformation. \n",
    "\n",
    "* Instructions\n",
    "\n",
    "    * Store LabelEncoder() in a variable named enc\n",
    "    * Using the encoder's fit_transform() function, encode the hiking dataset's \"Accessible\" column. Call the new column Accessible_enc.\n",
    "    * Compare the two columns side-by-side to see the encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e227fa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accessible_enc Accessible\n",
      "0               1          Y\n",
      "1               0          N\n",
      "2               0          N\n",
      "3               0          N\n",
      "4               0          N\n"
     ]
    }
   ],
   "source": [
    "# Set up the LabelEncoder object\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# Apply the encoding to the \"Accessible\" column\n",
    "hiking[\"Accessible_enc\"] = enc.fit_transform(hiking[\"Accessible\"])\n",
    "\n",
    "# Compare the two columns\n",
    "print(hiking[[\"Accessible_enc\", \"Accessible\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc1b96",
   "metadata": {},
   "source": [
    "### Encoding categorical variables - one-hot\n",
    "\n",
    "One of the columns in the volunteer dataset, category_desc, gives category descriptions for the volunteer opportunities listed. Because it is a categorical variable with more than two categories, we need to use one-hot encoding to transform this column numerically. Use Pandas' `get_dummies()` function to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cde4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Education  Emergency Preparedness  Environment  Health  \\\n",
      "0          0                       0            0       0   \n",
      "1          0                       0            0       0   \n",
      "2          0                       0            0       0   \n",
      "3          0                       0            0       0   \n",
      "4          0                       0            1       0   \n",
      "\n",
      "   Helping Neighbors in Need  Strengthening Communities  \n",
      "0                          0                          0  \n",
      "1                          0                          1  \n",
      "2                          0                          1  \n",
      "3                          0                          1  \n",
      "4                          0                          0  \n"
     ]
    }
   ],
   "source": [
    "# Transform the category_desc column\n",
    "category_enc = pd.get_dummies(volunteer[\"category_desc\"])\n",
    "\n",
    "# Take a look at the encoded columns\n",
    "print(category_enc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c262e",
   "metadata": {},
   "source": [
    "### Engineering numerical features - taking an average\n",
    "\n",
    "A good use case for taking an aggregate statistic to create a new feature is to take the mean of columns. Here, you have a DataFrame of running times named running_times_5k. For each name in the dataset, take the mean of their 5 run times.\n",
    "\n",
    "* Instructions\n",
    "\n",
    "    * Create a list of the columns you want to take the average of and store it in a variable named run_columns.\n",
    "    * Use apply to take the mean() of the list of columns and remember to set axis=1. Use lambda row: in the apply.\n",
    "    * Print out the DataFrame to see the mean column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c0ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'name':['Sue', 'Mark', 'Sean', 'Erin', 'Jenny', 'Russell'], \n",
    "    'run1':[20.1, 16.5, 23.5, 21.7, 25.8, 30.9], \n",
    "    'run2':[18.5, 17.1, 25.1, 21.1, 27.1, 29.6], \n",
    "    'run3':[19.6, 16.9, 25.2, 20.9, 26.1, 31.4], \n",
    "    'run4':[20.3, 17.6, 24.6, 22.1, 26.7, 30.4], \n",
    "    'run5':[18.3, 17.3, 23.9, 22.2, 26.9, 29.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e169d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_times_5k = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac81fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  run1  run2  run3  run4  run5   mean\n",
      "0      Sue  20.1  18.5  19.6  20.3  18.3  19.36\n",
      "1     Mark  16.5  17.1  16.9  17.6  17.3  17.08\n",
      "2     Sean  23.5  25.1  25.2  24.6  23.9  24.46\n",
      "3     Erin  21.7  21.1  20.9  22.1  22.2  21.60\n",
      "4    Jenny  25.8  27.1  26.1  26.7  26.9  26.52\n",
      "5  Russell  30.9  29.6  31.4  30.4  29.9  30.44\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the columns to average\n",
    "run_columns = [\"run1\", \"run2\", \"run3\", \"run4\", \"run5\"]\n",
    "\n",
    "# Use apply to create a mean column\n",
    "running_times_5k[\"mean\"] = running_times_5k.apply(lambda row: row[run_columns].mean(), axis=1)\n",
    "\n",
    "# Take a look at the results\n",
    "print(running_times_5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2fab81",
   "metadata": {},
   "source": [
    "### Engineering numerical features - datetime\n",
    "\n",
    "There are several columns in the volunteer dataset comprised of datetimes. Let's take a look at the start_date_date column and extract just the month to use as a feature for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f93841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  start_date_converted  start_date_month\n",
      "0           2011-07-30                 7\n",
      "1           2011-02-01                 2\n",
      "2           2011-01-29                 1\n",
      "3           2011-02-14                 2\n",
      "4           2011-02-05                 2\n"
     ]
    }
   ],
   "source": [
    "# First, convert string column to date column\n",
    "volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\n",
    "\n",
    "# Extract just the month from the converted column\n",
    "volunteer[\"start_date_month\"] = volunteer[\"start_date_converted\"].apply(lambda row: row.month)\n",
    "\n",
    "# Take a look at the converted and new month columns\n",
    "print(volunteer[[\"start_date_converted\", \"start_date_month\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b469d79",
   "metadata": {},
   "source": [
    "### Engineering features from strings - extraction\n",
    "\n",
    "The Length column in the hiking dataset is a column of strings, but contained in the column is the mileage for the hike. We're going to extract this mileage using regular expressions, and then use a lambda in Pandas to apply the extraction to the DataFrame.\n",
    "* Instructions\n",
    "\n",
    "    * Create a pattern that will extract numbers and decimals from text, using `\\d+ to get numbers` and `\\. to get decimals`, and pass it into re's compile function.\n",
    "    * Use re's match function to search the text, passing in the pattern and the length text.\n",
    "    * Use the matched mile's group() attribute to extract the matched pattern, making sure to match group 0, and pass it into float.\n",
    "    * Apply the `return_mileage()` function to the hiking[\"Length\"] column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07247681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6290caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Length  Length_num\n",
      "0   0.8 miles        0.80\n",
      "1    1.0 mile        1.00\n",
      "2  0.75 miles        0.75\n",
      "3   0.5 miles        0.50\n",
      "4   0.5 miles        0.50\n"
     ]
    }
   ],
   "source": [
    "# Write a pattern to extract numbers and decimals\n",
    "def return_mileage(length):\n",
    "    pattern = re.compile(r\"\\d+\\.\\d+\")\n",
    "    \n",
    "    # Search the text for matches\n",
    "    mile = re.match(pattern, length)\n",
    "    \n",
    "    # If a value is returned, use group(0) to return the found value\n",
    "    if mile is not None:\n",
    "        return float(mile.group(0))\n",
    "        \n",
    "# Apply the function to the Length column and take a look at both columns\n",
    "hiking[\"Length_num\"] = hiking[\"Length\"].dropna(axis=0).apply(lambda row: return_mileage(row))\n",
    "print(hiking[[\"Length\", \"Length_num\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703c35a",
   "metadata": {},
   "source": [
    "## Engineering features from strings - tf/idf\n",
    "\n",
    "Let's transform the volunteer dataset's title column into a text vector, to use in a prediction task in the next exercise.\n",
    "* Instructions\n",
    "\n",
    "    * Store the volunteer[\"title\"] column in a variable named title_text.\n",
    "    * Use the tfidf_vec vectorizer's fit_transform() function on title_text to transform the text into a tf-idf vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c383fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer['title'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1bce5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Volunteers Needed For Rise Up & Stay Put! Home...\n",
       "1                                         Web designer\n",
       "2        Urban Adventures - Ice Skating at Lasker Rink\n",
       "3    Fight global hunger and support women farmers ...\n",
       "4                                        Stop 'N' Swap\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37280aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c280cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = volunteer[['title', 'category_desc']]\n",
    "temp_df = temp_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7e9cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the title text\n",
    "title_text = temp_df[\"title\"]\n",
    "\n",
    "# Create the vectorizer method\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# Transform the text into tf-idf vectors\n",
    "text_tfidf = tfidf_vec.fit_transform(title_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25c6572b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 1089)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec782e2",
   "metadata": {},
   "source": [
    "## Text classification using tf/idf vectors\n",
    "\n",
    "Now that we've encoded the volunteer dataset's title column into tf/idf vectors, let's use those vectors to try to predict the category_desc column.\n",
    "* Instructions\n",
    "\n",
    "    * Using train_test_split, split the text_tfidf vector, along with your y variable, into training and test sets. Set the stratify parameter equal to y, since the class distribution is uneven. Notice that we have to run the toarray() method on the tf/idf vector, in order to get in it the proper format for scikit-learn.\n",
    "    * Use Naive Bayes' fit() method on the X_train and y_train variables.\n",
    "    * Print out the score() of the X_test and y_test variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d664dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nb = GaussianNB(priors=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb59f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5935483870967742\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset according to the class distribution of category_desc\n",
    "y = temp_df[\"category_desc\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_tfidf.toarray(), y, stratify=y)\n",
    "\n",
    "# Fit the model to the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Print out the model's accuracy\n",
    "print(nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f8f97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84779ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982a88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1580e905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
