{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56bd4f21",
   "metadata": {},
   "source": [
    "### Compiling a sequential model\n",
    "\n",
    "In this exercise, you will work towards classifying letters from the Sign Language MNIST dataset; however, you will adopt a different network architecture than what you used in the previous exercise. There will be fewer layers, but more nodes. You will also apply dropout to prevent overfitting. Finally, you will compile the model to use the adam optimizer and the categorical_crossentropy loss. You will also use a method in keras to summarize your model's architecture. Note that keras has been imported from tensorflow for you and a sequential keras model has been defined as model.\n",
    "\n",
    "***Instructions***\n",
    "* In the first dense layer, set the number of nodes to 16, the activation to sigmoid, and the input_shape to (784,).\n",
    "* Apply dropout at a rate of 25% to the first layer's output.\n",
    "* Set the output layer to be dense, have 4 nodes, and use a softmax activation function.\n",
    "* Compile the model using an adam optimizer and categorical_crossentropy loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337ec945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b3b9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 12,732\n",
      "Trainable params: 12,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a Keras sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define the first dense layer\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the second dense layer\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax', input_shape=(784,)))\n",
    "\n",
    "# Print the model architecture\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019631ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 12,880\n",
      "Trainable params: 12,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the first dense layer\n",
    "model.add(tf.keras.layers.Dense(16, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "# Apply dropout to the first layer's output\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ff6f7",
   "metadata": {},
   "source": [
    "### Defining a multiple input model\n",
    "\n",
    "In some cases, the sequential API will not be sufficiently flexible to accommodate your desired model architecture and you will need to use the functional API instead. If, for instance, you want to train two models with different architectures jointly, you will need to use the functional API to do this. In this exercise, we will see how to do this. We will also use the .summary() method to examine the joint model's architecture.\n",
    "\n",
    "Note that keras has been imported from tensorflow for you. Additionally, the input layers of the first and second models have been defined as m1_inputs and m2_inputs, respectively. Note that the two models have the same architecture, but one of them uses a sigmoid activation in the first layer and the other uses a relu.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    " * Pass model 1's input layer to its first layer and model 1's first layer to its second layer.\n",
    " * Pass model 2's input layer to its first layer and model 2's first layer to its second layer.\n",
    " * Use the add() operation to combine the second layers of model 1 and model 2.\n",
    "    Complete the functional model definition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7032cb4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "constant() missing 1 required positional argument: 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10747/3989283624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm1_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: constant() missing 1 required positional argument: 'value'"
     ]
    }
   ],
   "source": [
    "m1_inputs = tf.constant(shape=[None,784], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
    "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
    "\n",
    "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
    "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
    "\n",
    "# Merge model outputs and define a functional model\n",
    "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
    "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620fa8c",
   "metadata": {},
   "source": [
    "### Training with Keras\n",
    "\n",
    "In this exercise, we return to our sign language letter classification problem. We have 2000 images of four letters--A, B, C, and D--and we want to classify them with a high level of accuracy. We will complete all parts of the problem, including the model definition, compilation, and training.\n",
    "\n",
    "Note that keras has been imported from tensorflow for you. Additionally, the features are available as sign_language_features and the targets are available as sign_language_labels.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Define a sequential model named model.\n",
    "* Set the output layer to be dense, have 4 nodes, and use a softmax activation function.\n",
    "* Compile the model with the SGD optimizer and categorical_crossentropy loss.\n",
    "* Complete the fitting operation and set the number of epochs to 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a57847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>146</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>149.1</th>\n",
       "      <th>149.2</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>...</th>\n",
       "      <th>0.1</th>\n",
       "      <th>15</th>\n",
       "      <th>55</th>\n",
       "      <th>63</th>\n",
       "      <th>37.2</th>\n",
       "      <th>61.1</th>\n",
       "      <th>77.2</th>\n",
       "      <th>65.1</th>\n",
       "      <th>38.1</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>147</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>198</td>\n",
       "      <td>193</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>106</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>160</td>\n",
       "      <td>164</td>\n",
       "      <td>168</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>163</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>170</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>233</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  142  143  146  148  149  149.1  149.2  150  151  ...  0.1   15   55  \\\n",
       "0  0  141  142  144  145  147    149    150  151  152  ...  173  179  179   \n",
       "1  1  156  157  160  162  164    166    169  171  171  ...  181  197  195   \n",
       "2  3   63   26   65   86   97    106    117  123  128  ...  175  179  180   \n",
       "3  1  156  160  164  168  172    175    178  180  182  ...  108  107  106   \n",
       "4  0  159  163  167  168  170    173    175  178  178  ...  173  233  235   \n",
       "\n",
       "    63  37.2  61.1  77.2  65.1  38.1   23  \n",
       "0  180   181   181   182   182   183  183  \n",
       "1  193   193   191   192   198   193  182  \n",
       "2  182   183   183   184   185   185  185  \n",
       "3  110   111   108   108   102    84   70  \n",
       "4  235   236   235   235   236   235  235  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign = pd.read_csv('../slmnist.csv', nrows=1000)\n",
    "sign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "541c341b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 785)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af72984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_language_features = sign.iloc[:, 1:].values\n",
    "sign_language_labels = sign.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95948ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_language_labels = pd.get_dummies(sign_language_labels).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ba40771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784) \n",
      " (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(sign_language_features.shape, '\\n', sign_language_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fe0b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 65161.9570\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3860\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3858\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3856\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.3855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2718050d90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define a hidden layer\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax', input_shape=(784,)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('SGD', loss='categorical_crossentropy')\n",
    "\n",
    "# Complete the fitting operation\n",
    "model.fit(sign_language_features, sign_language_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686178e",
   "metadata": {},
   "source": [
    "### Metrics and validation with Keras\n",
    "\n",
    "We trained a model to predict sign language letters in the previous exercise, but it is unclear how successful we were in doing so. In this exercise, we will try to improve upon the interpretability of our results. Since we did not use a validation split, we only observed performance improvements within the training set; however, it is unclear how much of that was due to overfitting. Furthermore, since we did not supply a metric, we only saw decreases in the loss function, which do not have any clear interpretation.\n",
    "\n",
    "Note that keras has been imported for you from tensorflow.\n",
    "\n",
    "***Instructions***\n",
    "\n",
    "* Set the first dense layer to have 32 nodes, use a sigmoid activation function, and have an input shape of (784,).\n",
    "* Use the root mean square propagation optimizer, a categorical crossentropy loss, and the accuracy metric.\n",
    "* Set the number of epochs to 10 and use 10% of the dataset for validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2778b271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 1s 8ms/step - loss: 1.4293 - accuracy: 0.2511 - val_loss: 1.3802 - val_accuracy: 0.2700\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3880 - accuracy: 0.2500 - val_loss: 1.3796 - val_accuracy: 0.2800\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3864 - accuracy: 0.2611 - val_loss: 1.3817 - val_accuracy: 0.2800\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3862 - accuracy: 0.2678 - val_loss: 1.3875 - val_accuracy: 0.2600\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3871 - accuracy: 0.2556 - val_loss: 1.3865 - val_accuracy: 0.2600\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3867 - accuracy: 0.2611 - val_loss: 1.3831 - val_accuracy: 0.2800\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 1.3867 - accuracy: 0.2589 - val_loss: 1.3854 - val_accuracy: 0.2800\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3870 - accuracy: 0.2678 - val_loss: 1.3864 - val_accuracy: 0.2800\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3868 - accuracy: 0.2478 - val_loss: 1.3835 - val_accuracy: 0.2800\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 1.3882 - accuracy: 0.2622 - val_loss: 1.3813 - val_accuracy: 0.2800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2718cb86a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model.add(tf.keras.layers.Dense(32, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "# Add activation function to classifier\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Set the optimizer, loss function, and metrics\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add the number of epochs and the validation split\n",
    "model.fit(sign_language_features, sign_language_labels, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979feb51",
   "metadata": {},
   "source": [
    "### Overfitting detection\n",
    "\n",
    "In this exercise, we'll work with a small subset of the examples from the original sign language letters dataset. A small sample, coupled with a heavily-parameterized model, will generally lead to overfitting. This means that your model will simply memorize the class of each example, rather than identifying features that generalize to many examples.\n",
    "\n",
    "You will detect overfitting by checking whether the validation sample loss is substantially higher than the training sample loss and whether it increases with further training. With a small sample and a high learning rate, the model will struggle to converge on an optimum. You will set a low learning rate for the optimizer, which will make it easier to identify overfitting.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Define a sequential model in keras named model.\n",
    "* Add a first dense layer with 1024 nodes, a relu activation, and an input shape of (784,).\n",
    "* Set the learning rate to 0.001.\n",
    "* Set the fit() operation to iterate over the full sample 50 times and use 50% of the sample for validation purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "decace92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/.local/bin/.virtualenvs/myEnv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 18ms/step - loss: 556.7875 - accuracy: 0.3180 - val_loss: 224.4320 - val_accuracy: 0.3840\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 72.3855 - accuracy: 0.6060 - val_loss: 50.7012 - val_accuracy: 0.6920\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 19.3750 - accuracy: 0.7440 - val_loss: 9.1214 - val_accuracy: 0.7540\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 4.0337 - accuracy: 0.8480 - val_loss: 0.9520 - val_accuracy: 0.9500\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.3838 - accuracy: 0.9200 - val_loss: 0.6762 - val_accuracy: 0.9720\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2409 - accuracy: 0.9900 - val_loss: 1.3715 - val_accuracy: 0.9460\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1805 - accuracy: 0.9780 - val_loss: 1.0078 - val_accuracy: 0.9460\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3552 - accuracy: 0.9740 - val_loss: 0.4678 - val_accuracy: 0.9780\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.2240 - accuracy: 0.9840 - val_loss: 0.1578 - val_accuracy: 0.9820\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0896 - accuracy: 0.9860 - val_loss: 0.5017 - val_accuracy: 0.9520\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 7.3497 - accuracy: 0.8760 - val_loss: 14.2536 - val_accuracy: 0.7480\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5.5108 - accuracy: 0.8680 - val_loss: 2.5219 - val_accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4.0224 - accuracy: 0.8740 - val_loss: 1.0506 - val_accuracy: 0.9500\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.9740 - val_loss: 2.4491 - val_accuracy: 0.9080\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.6218 - accuracy: 0.9500 - val_loss: 2.3455 - val_accuracy: 0.9360\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.5713 - accuracy: 0.9660 - val_loss: 0.7897 - val_accuracy: 0.9760\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.3860 - accuracy: 0.9820 - val_loss: 1.6623 - val_accuracy: 0.9580\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4695 - accuracy: 0.9720 - val_loss: 0.5768 - val_accuracy: 0.9660\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.3066 - accuracy: 0.9880 - val_loss: 0.1558 - val_accuracy: 0.9880\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0432 - accuracy: 0.9880 - val_loss: 0.1933 - val_accuracy: 0.9860\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 1.1204 - accuracy: 0.9640 - val_loss: 0.2451 - val_accuracy: 0.9760\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.5743 - accuracy: 0.9540 - val_loss: 0.3599 - val_accuracy: 0.9840\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2.2885 - accuracy: 0.9320 - val_loss: 0.3898 - val_accuracy: 0.9880\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.8431 - accuracy: 0.9680 - val_loss: 0.7739 - val_accuracy: 0.9880\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.2006 - accuracy: 0.9940 - val_loss: 0.2554 - val_accuracy: 0.9880\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7800 - val_accuracy: 0.9880\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 2.7776e-05 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.9880\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 4.9088e-05 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.9880\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 7.0027e-06 - accuracy: 1.0000 - val_loss: 0.8342 - val_accuracy: 0.9880\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 3.3025e-06 - accuracy: 1.0000 - val_loss: 0.8286 - val_accuracy: 0.9880\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 2.5355e-06 - accuracy: 1.0000 - val_loss: 0.8253 - val_accuracy: 0.9880\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 2.0641e-06 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 0.9880\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.7856e-06 - accuracy: 1.0000 - val_loss: 0.8215 - val_accuracy: 0.9880\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6359e-06 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.9880\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.4269e-06 - accuracy: 1.0000 - val_loss: 0.8182 - val_accuracy: 0.9880\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.2922e-06 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.9880\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.2122e-06 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.9880\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0811e-06 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.9880\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1.0036e-06 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.9880\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 9.4592e-07 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.9880\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 8.8276e-07 - accuracy: 1.0000 - val_loss: 0.8118 - val_accuracy: 0.9880\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 8.2555e-07 - accuracy: 1.0000 - val_loss: 0.8109 - val_accuracy: 0.9880\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 7.7644e-07 - accuracy: 1.0000 - val_loss: 0.8100 - val_accuracy: 0.9880\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 7.2686e-07 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.9880\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6.8872e-07 - accuracy: 1.0000 - val_loss: 0.8086 - val_accuracy: 0.9880\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 6.5201e-07 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.9880\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 6.1554e-07 - accuracy: 1.0000 - val_loss: 0.8073 - val_accuracy: 0.9880\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5.7907e-07 - accuracy: 1.0000 - val_loss: 0.8064 - val_accuracy: 0.9880\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 5.5714e-07 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.9880\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 5.2234e-07 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f27194a4190>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sequential model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Add activation function to classifier\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Complete the model fit operation\n",
    "model.fit(sign_language_features, sign_language_labels, epochs=50, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972ac3a",
   "metadata": {},
   "source": [
    "### Preparing to train with Estimators\n",
    "\n",
    "For this exercise, we'll return to the King County housing transaction dataset from chapter 2. We will again develop and train a machine learning model to predict house prices; however, this time, we'll do it using the estimator API.\n",
    "\n",
    "Rather than completing everything in one step, we'll break this procedure down into parts. We'll begin by defining the feature columns and loading the data. In the next exercise, we'll define and train a premade estimator. Note that feature_column has been imported for you from tensorflow. Additionally, numpy has been imported as np, and the Kings County housing dataset is available as a pandas DataFrame: housing.\n",
    "\n",
    "***Instructions***\n",
    "\n",
    "* Complete the feature column for bedrooms and add another numeric feature column for bathrooms. Use bedrooms and bathrooms as the keys.\n",
    "* Create a list of the feature columns, feature_list, in the order in which they were defined.\n",
    "* Set labels to be equal to the price column in housing.\n",
    "* Complete the bedrooms entry of the features dictionary and add another entry for bathrooms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4842c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('../kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14503a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns for bedrooms and bathrooms\n",
    "bedrooms = tf.feature_column.numeric_column(\"bedrooms\")\n",
    "bathrooms = tf.feature_column.numeric_column(\"bathrooms\")\n",
    "\n",
    "# Define the list of feature columns\n",
    "feature_list = [bedrooms, bathrooms]\n",
    "\n",
    "def input_fn():\n",
    "\t# Define the labels\n",
    "\tlabels = np.array(housing['price'])\n",
    "\t# Define the features\n",
    "\tfeatures = {'bedrooms':np.array(housing['bedrooms']), \n",
    "                'bathrooms':np.array(housing['bathrooms'])}\n",
    "\treturn features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed5de269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp6z1ordxy\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp6z1ordxy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/ahmed/.local/bin/.virtualenvs/myEnv/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/ahmed/.local/bin/.virtualenvs/myEnv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:87: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp6z1ordxy/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 426471400000.0, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1...\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp6z1ordxy/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1...\n",
      "INFO:tensorflow:Loss for final step: 426471400000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x7f27137252b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model and set the number of steps\n",
    "model = tf.estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[2,2])\n",
    "model.train(input_fn, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9454abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpm5be_jd5\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpm5be_jd5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/.local/bin/.virtualenvs/myEnv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpm5be_jd5/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 426471400000.0, step = 0\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2...\n",
      "INFO:tensorflow:Saving checkpoints for 2 into /tmp/tmpm5be_jd5/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2...\n",
      "INFO:tensorflow:Loss for final step: 426469850000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x7f2713537850>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model and set the number of steps\n",
    "model = tf.estimator.LinearRegressor(feature_columns=feature_list)\n",
    "model.train(input_fn, steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bc342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
