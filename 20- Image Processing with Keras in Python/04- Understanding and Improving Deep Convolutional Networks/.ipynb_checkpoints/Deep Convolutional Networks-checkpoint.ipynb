{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f95f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 23:36:08.553521: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-21 23:36:08.553567: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeca48f",
   "metadata": {},
   "source": [
    "### Creating a deep learning network\n",
    "\n",
    "A deep convolutional neural network is a network that has more than one layer. Each layer in a deep network receives its input from the preceding layer, with the very first layer receiving its input from the images used as training or test data.\n",
    "\n",
    "Here, you will create a network that has two convolutional layers.\n",
    "* Instructions\n",
    "\n",
    "    * The first convolutional layer is the input layer of the network. This should have 15 units with kernels of 2 by 2 pixels. It should have a 'relu' activation function. It can use the variables img_rows and img_cols to define its input_shape.\n",
    "    * The second convolutional layer receives its inputs from the first layer. It should have 5 units with kernels of 2 by 2 pixels. It should also have a 'relu' activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b5e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537dc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7673b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), \\\n",
    "                    (test_data, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36505bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[(train_labels >= 0)\\\n",
    "                        & (train_labels < 3)][0:50].reshape(-1, 28, 28, 1)\n",
    "train_labels = train_labels[(train_labels >= 0) & (train_labels < 3)][0:50]\n",
    "train_labels = pd.get_dummies(train_labels).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ebb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[(test_labels >= 0) & (test_labels < 3)][0:10].reshape(-1, 28, 28, 1)\n",
    "test_labels = test_labels[(test_labels >= 0) & (test_labels < 3)][0:10]\n",
    "test_labels = pd.get_dummies(test_labels).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea6cee",
   "metadata": {},
   "source": [
    "### Keras pooling layers\n",
    "\n",
    "Keras implements a pooling operation as a layer that can be added to CNNs between other layers. In this exercise, you will construct a convolutional neural network similar to the one you have constructed before:\n",
    "\n",
    "Convolution => Convolution => Flatten => Dense\n",
    "\n",
    "However, you will also add a pooling layer. The architecture will add a single max-pooling layer between the convolutional layer and the dense layer with a pooling of 2x2:\n",
    "\n",
    "Convolution => Max pooling => Convolution => Flatten => Dense\n",
    "\n",
    "A Sequential model along with Dense, Conv2D, Flatten, and MaxPool2D objects are available in your workspace.\n",
    "* Instructions\n",
    "\n",
    "    * Add an input convolutional layer (15 units, kernel size of 2, relu activation).\n",
    "    * Add a maximum pooling operation (pooling over windows of size 2x2).\n",
    "    * Add another convolution layer (5 units, kernel size of 2, relu activation).\n",
    "    * Flatten the output of the second convolution and add a Dense layer for output (3 categories, softmax activation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fcf0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 27, 27, 15)        75        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 15)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 5)         305       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 720)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 2163      \n",
      "=================================================================\n",
      "Total params: 2,543\n",
      "Trainable params: 2,543\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 23:36:10.941267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-21 23:36:10.941301: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-21 23:36:10.941328: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Rabie): /proc/driver/nvidia/version does not exist\n",
      "2021-12-21 23:36:10.941576: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPool2D\n",
    "model2 = Sequential()\n",
    "\n",
    "# Add a convolutional layer\n",
    "model2.add(Conv2D(15, kernel_size=2, activation='relu', \n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a pooling operation\n",
    "model2.add(MaxPool2D(2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model2.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c14c9b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 23:36:11.242270: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-21 23:36:11.242795: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2394475000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4/4 [==============================] - 16s 154ms/step - loss: 36.8751 - accuracy: 0.2500 - val_loss: 7.7464 - val_accuracy: 0.3000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 8.3011 - accuracy: 0.3667 - val_loss: 6.6385 - val_accuracy: 0.8000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.5414 - accuracy: 0.7300 - val_loss: 3.3866 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0140 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.014004053547978401, 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model2.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to training data \n",
    "model2.fit(train_data, train_labels, \n",
    "          validation_split=0.2, \n",
    "          epochs=3, batch_size=10)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "model2.evaluate(test_data, test_labels, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e466fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# This checkpoint object will store the model parameters\n",
    "# in the file \"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint('weights.hdf5', monitor='val_loss', save_best_only=True)\n",
    "# Store in a list to be used during training\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24269b9",
   "metadata": {},
   "source": [
    "### Plot the learning curves\n",
    "\n",
    "During learning, the model will store the loss function evaluated in each epoch. Looking at the learning curves can tell us quite a bit about the learning process. In this exercise, you will plot the learning and validation loss curves for a model that you will train.\n",
    "* Instructions\n",
    "\n",
    "    * Fit the model to the training data (train_data).\n",
    "    * Use a validation split of 20%, 3 epochs and batch size of 10.\n",
    "    * Plot the training loss.\n",
    "    * Plot the validation loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49dc3cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.0735 - accuracy: 0.8250 - val_loss: 0.7945 - val_accuracy: 0.8000\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4216 - accuracy: 0.9250 - val_loss: 0.8635 - val_accuracy: 0.9000\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6182 - accuracy: 0.9000 - val_loss: 0.9676 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the model and store the training object\n",
    "training = model2.fit(train_data, train_labels, validation_split=0.2, epochs=3, batch_size=10, callbacks=callbacks_list)\n",
    "\n",
    "# Extract the history from the training object\n",
    "history = training.history\n",
    "\n",
    "# Plot the training loss \n",
    "plt.plot(history['loss'])\n",
    "# Plot the validation loss\n",
    "plt.plot(history['val_loss'])\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c2bb60",
   "metadata": {},
   "source": [
    "### Using stored weights to predict in a test set\n",
    "\n",
    "Model weights stored in an hdf5 file can be reused to populate an untrained model. Once the weights are loaded into this model, it behaves just like a model that has been trained to reach these weights. For example, you can use this model to make predictions from an unseen data set (e.g. test_data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7134d477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3058617e-17, 1.9233330e-24, 1.0000000e+00],\n",
       "       [9.2559754e-15, 1.0000000e+00, 1.5174397e-19],\n",
       "       [6.4248942e-22, 1.0000000e+00, 6.5403372e-19]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the weights from file\n",
    "model2.load_weights('weights.hdf5')\n",
    "\n",
    "# Predict from the first three images in the test data\n",
    "model2.predict(test_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304ed9f",
   "metadata": {},
   "source": [
    "### Adding dropout to your network\n",
    "\n",
    "Dropout is a form of regularization that removes a different random subset of the units in a layer in each round of training. In this exercise, we will add dropout to the convolutional neural network that we have used in previous exercises:\n",
    "\n",
    "* Convolution (15 units, kernel size 2, 'relu' activation)\n",
    "* Dropout (20%)\n",
    "* Convolution (5 units, kernel size 2, 'relu' activation)\n",
    "* Flatten\n",
    "* Dense (3 units, 'softmax' activation)\n",
    "\n",
    "A Sequential model along with Dense, Conv2D, Flatten, and Dropout objects are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfd6f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(15, kernel_size=2, activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add a dropout layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e59136e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() missing 1 required positional argument: 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17432/2328160102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Add a convolutional layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Add batch normalization layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/bin/.virtualenvs/myEnv/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add() missing 1 required positional argument: 'layer'"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization,Conv2D\n",
    "model3 = Sequential\n",
    "\n",
    "# Add a convolutional layer\n",
    "model3.add(Conv2D(15, kernel_size=2, activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "# Add batch normalization layer\n",
    "model3.add(BatchNormalization())\n",
    "\n",
    "# Add another convolutional layer\n",
    "model3.add(Conv2D(5, kernel_size=2, activation='relu'))\n",
    "\n",
    "# Flatten and feed to output layer\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa00c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1cdbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1244efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844862b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
